{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a13ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aditya Bankar\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56060a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Discrete(3).sample() #Used to create Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c509bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5713243 , 0.11105458, 0.11222368],\n",
       "       [0.09095743, 0.9781431 , 0.18303299],\n",
       "       [0.89597297, 0.67576754, 0.7503064 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(0,1,shape=(3,3)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f125acd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('height', 1), ('speed', array([30.148188], dtype=float32))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict({'height':Discrete(2), \"speed\":Box(0,100,shape=(1,))}).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d248be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiBinary(4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiBinary(4) #Used to create This space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c565238a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiBinary(4).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa52618e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiDiscrete([5 2 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiDiscrete([5,2,2])#Used to make space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dd0f133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiDiscrete([5,2,2]).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebe2c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ShowerEnv(Env):\n",
    "#     def __init__(self):\n",
    "#         self.action_space = Discrete(3)\n",
    "#         self.observation_space = Box(low=np.array([0]), high=np.array([100]))\n",
    "#         self.state = 38 + random.randint(-3,3)\n",
    "#         self.shower_length = 60\n",
    "    \n",
    "        \n",
    "#     def step(self,action):\n",
    "#         self.state += action - 1\n",
    "#         self.shower_length -= 1\n",
    "        \n",
    "#         if self.state >= 37and self.state<=39:\n",
    "#             reward = 1\n",
    "#         else:\n",
    "#             reward = -1\n",
    "            \n",
    "#         if shower.length <= 0:\n",
    "#             done = True\n",
    "#         else:\n",
    "#             done = False\n",
    "            \n",
    "#         info={}\n",
    "        \n",
    "#         return self.state,reward,done,info\n",
    "#     def render(self):\n",
    "#         pass\n",
    "#     def reset(self):\n",
    "#         self.state = np.array([38+random.randint(-3,3)]).astype(float)\n",
    "#         self.shower_length = 60\n",
    "#         return self.state\n",
    "        \n",
    "    \n",
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        # Actions we can take, down, stay, up\n",
    "        self.action_space = Discrete(3)\n",
    "        # Temperature array\n",
    "        self.observation_space = Box(low=np.array([0]), high=np.array([100]))\n",
    "        # Set start temp\n",
    "        self.state = 38 + random.randint(-3,3)\n",
    "        # Set shower length\n",
    "        self.shower_length = 60\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Apply action\n",
    "        # 0 -1 = -1 temperature\n",
    "        # 1 -1 = 0 \n",
    "        # 2 -1 = 1 temperature \n",
    "        self.state += action -1 \n",
    "        # Reduce shower length by 1 second\n",
    "        self.shower_length -= 1 \n",
    "        \n",
    "        # Calculate reward\n",
    "        if self.state >=37 and self.state <=39: \n",
    "            reward =1 \n",
    "        else: \n",
    "            reward = -1 \n",
    "        \n",
    "        # Check if shower is done\n",
    "        if self.shower_length <= 0: \n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        # Apply temperature noise\n",
    "        #self.state += random.randint(-1,1)\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset shower temperature\n",
    "        self.state = np.array([38 + random.randint(-3,3)]).astype(float)\n",
    "        # Reset shower time\n",
    "        self.shower_length = 60 \n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c81e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ShowerEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3721332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.4359684], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b23860d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0fc0c00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-18\n",
      "Episode:2 Score:14\n",
      "Episode:3 Score:-26\n",
      "Episode:4 Score:-20\n",
      "Episode:5 Score:-26\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes + 1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()  # Render the environment without specifying a render mode\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(action)  # Unpack values directly here\n",
    "        score += reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "24b879d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya Bankar\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training','Logs')\n",
    "model = PPO('MlpPolicy',env,verbose = 1,tensorboard_log = log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "da87109b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_7\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60       |\n",
      "|    ep_rew_mean     | -31.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 702      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -31.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006886013 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | -5.84e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00102    |\n",
      "|    value_loss           | 64.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | -30.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 496        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01207112 |\n",
      "|    clip_fraction        | 0.0619     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | -7.25e-05  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 26.2       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.00676   |\n",
      "|    value_loss           | 65.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -31          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 518          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075976457 |\n",
      "|    clip_fraction        | 0.0457       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | -8.82e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 41.7         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00472     |\n",
      "|    value_loss           | 74           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -31.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 532         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005893765 |\n",
      "|    clip_fraction        | 0.0266      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 9.24e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.7        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    value_loss           | 65.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | -33.5      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 543        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 22         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00881318 |\n",
      "|    clip_fraction        | 0.0925     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 2.44e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 39.1       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.00669   |\n",
      "|    value_loss           | 72.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -28.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 554         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011503218 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -2.16e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 77.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -23          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 556          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062397355 |\n",
      "|    clip_fraction        | 0.0436       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 8.23e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 41           |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    value_loss           | 79.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -19.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 566         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010613594 |\n",
      "|    clip_fraction        | 0.0475      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.000375   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    value_loss           | 76.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | -18.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 575        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 35         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01031009 |\n",
      "|    clip_fraction        | 0.0334     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | 0.000537   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 29.7       |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.00313   |\n",
      "|    value_loss           | 53.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -21         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 577         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011753331 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.00575     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.8        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 78.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -19.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007534452 |\n",
      "|    clip_fraction        | 0.0832      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.0245     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    value_loss           | 63.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -19.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 585          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013808118 |\n",
      "|    clip_fraction        | 0.0554       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.000369     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 35.5         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.000148    |\n",
      "|    value_loss           | 74.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -16.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009018345 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.00532    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00971    |\n",
      "|    value_loss           | 68.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -17.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007689043 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.00381    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    value_loss           | 64.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -19.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005922521 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | -0.00853    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.5        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    value_loss           | 66.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -20.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009660009 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.00487     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    value_loss           | 61.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -17.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010106843 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.96       |\n",
      "|    explained_variance   | 0.00685     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.1        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 70.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -12.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 593          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062707015 |\n",
      "|    clip_fraction        | 0.0499       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.954       |\n",
      "|    explained_variance   | -0.00297     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30.2         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.000658    |\n",
      "|    value_loss           | 66.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -11.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008238642 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.971      |\n",
      "|    explained_variance   | -0.0123     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    value_loss           | 68.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x200d2469540>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps = 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4b325cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shower_path = os.path.abspath(os.path.join('Training', 'Saved Models', 'shower_PPO_model'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a08d44c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(shower_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "819d8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2b1fb574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya Bankar\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(shower_path,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "112110f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya Bankar\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aditya Bankar\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:243: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n",
      "  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24.0, 54.99090833947008)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model,env,n_eval_episodes = 10,render = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76055e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
